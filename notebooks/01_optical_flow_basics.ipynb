{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 — Optical Flow Basics\n",
    "\n",
    "Compute dense optical flow and derive obstacle risk and openness signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import load_config, ensure_demo_video, open_capture, iter_frames, release_capture\n",
    "from src.perception_flow import (\n",
    "    compute_optical_flow,\n",
    "    compute_flow_magnitude,\n",
    "    compute_obstacle_risk,\n",
    "    compute_openness,\n",
    "    visualize_flow,\n",
    "    visualize_flow_hsv,\n",
    ")\n",
    "\n",
    "config = load_config(\"configs/default.yaml\")\n",
    "video_path = ensure_demo_video(config)\n",
    "print(f\"Video: {video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test optical flow on a pair of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read two consecutive frames\n",
    "cap = open_capture(config)\n",
    "ok1, frame1 = cap.read()\n",
    "ok2, frame2 = cap.read()\n",
    "release_capture(cap)\n",
    "\n",
    "if not (ok1 and ok2):\n",
    "    raise RuntimeError(\"Failed to read frames\")\n",
    "\n",
    "# Convert to grayscale for flow computation\n",
    "gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Compute optical flow\n",
    "flow = compute_optical_flow(gray1, gray2, config)\n",
    "print(f\"Flow shape: {flow.shape}\")\n",
    "print(f\"Flow range: [{flow.min():.2f}, {flow.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert frames to RGB for visualization\n",
    "frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize flow with arrows\n",
    "flow_arrows = visualize_flow(frame2_rgb, flow, step=20)\n",
    "\n",
    "# Visualize flow with HSV color coding\n",
    "flow_hsv = visualize_flow_hsv(flow)\n",
    "\n",
    "# Visualize flow magnitude\n",
    "magnitude = compute_flow_magnitude(flow)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes[0, 0].imshow(frame1_rgb)\n",
    "axes[0, 0].set_title(\"Frame 1\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(frame2_rgb)\n",
    "axes[0, 1].set_title(\"Frame 2\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 0].imshow(flow_arrows)\n",
    "axes[1, 0].set_title(\"Optical Flow (Arrows)\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "im = axes[1, 1].imshow(magnitude, cmap=\"hot\")\n",
    "axes[1, 1].set_title(\"Flow Magnitude\")\n",
    "axes[1, 1].axis(\"off\")\n",
    "plt.colorbar(im, ax=axes[1, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute obstacle risk and openness signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute risk and openness\n",
    "risk_score = compute_obstacle_risk(flow, config)\n",
    "openness_score, preferred_direction = compute_openness(flow, config)\n",
    "\n",
    "print(f\"Obstacle Risk: {risk_score:.3f}\")\n",
    "print(f\"Openness Score: {openness_score:.3f}\")\n",
    "print(f\"Preferred Direction: {preferred_direction}\")\n",
    "\n",
    "# Visualize central region used for risk computation\n",
    "h, w = magnitude.shape\n",
    "central_region = config[\"risk\"][\"central_region\"]\n",
    "x_start = int(w * central_region[0])\n",
    "x_end = int(w * central_region[1])\n",
    "\n",
    "vis_frame = frame2_rgb.copy()\n",
    "cv2.rectangle(vis_frame, (x_start, 0), (x_end, h), (255, 0, 0), 2)\n",
    "cv2.line(vis_frame, (w // 2, 0), (w // 2, h), (0, 255, 0), 2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(vis_frame)\n",
    "plt.title(f\"Risk Region (blue) | Risk={risk_score:.3f} | Openness={openness_score:.3f} | Direction={preferred_direction}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on full video sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process video and collect signals\n",
    "cap = open_capture(config)\n",
    "max_frames = config[\"video\"].get(\"max_frames\") or 150  # Limit for testing\n",
    "\n",
    "risk_scores = []\n",
    "openness_scores = []\n",
    "preferred_directions = []\n",
    "\n",
    "prev_gray = None\n",
    "frame_idx = 0\n",
    "\n",
    "for idx, frame in tqdm(iter_frames(cap, max_frames=max_frames, convert_rgb=False), total=max_frames):\n",
    "    curr_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if prev_gray is not None:\n",
    "        flow = compute_optical_flow(prev_gray, curr_gray, config)\n",
    "        risk = compute_obstacle_risk(flow, config)\n",
    "        openness, direction = compute_openness(flow, config)\n",
    "        \n",
    "        risk_scores.append(risk)\n",
    "        openness_scores.append(openness)\n",
    "        preferred_directions.append(1 if direction == \"right\" else -1)\n",
    "    \n",
    "    prev_gray = curr_gray\n",
    "    frame_idx += 1\n",
    "\n",
    "release_capture(cap)\n",
    "\n",
    "print(f\"Processed {frame_idx} frames\")\n",
    "print(f\"Risk range: [{min(risk_scores):.3f}, {max(risk_scores):.3f}]\")\n",
    "print(f\"Openness range: [{min(openness_scores):.3f}, {max(openness_scores):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot signals over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "frames = np.arange(len(risk_scores))\n",
    "\n",
    "# Risk scores\n",
    "axes[0].plot(frames, risk_scores, label=\"Risk Score\", color=\"red\")\n",
    "axes[0].axhline(config[\"risk\"][\"thresholds\"][\"avoid\"], color=\"orange\", linestyle=\"--\", label=\"Avoid Threshold\")\n",
    "axes[0].axhline(config[\"risk\"][\"thresholds\"][\"stop\"], color=\"darkred\", linestyle=\"--\", label=\"Stop Threshold\")\n",
    "axes[0].set_ylabel(\"Risk Score\")\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Openness scores\n",
    "axes[1].plot(frames, openness_scores, label=\"Openness Score\", color=\"blue\")\n",
    "axes[1].axhline(0, color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "axes[1].set_ylabel(\"Openness (L-R)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Preferred direction\n",
    "axes[2].plot(frames, preferred_directions, label=\"Preferred Direction\", color=\"green\", drawstyle=\"steps-post\")\n",
    "axes[2].set_ylabel(\"Direction (±1)\")\n",
    "axes[2].set_xlabel(\"Frame\")\n",
    "axes[2].set_ylim([-1.5, 1.5])\n",
    "axes[2].set_yticks([-1, 0, 1])\n",
    "axes[2].set_yticklabels([\"Left\", \"Center\", \"Right\"])\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Optical Flow-Based Perception Signals\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "Phase 2 verification:\n",
    "- Optical flow computation works on frame pairs\n",
    "- Flow magnitude is visualized correctly\n",
    "- Risk and openness signals are computed and show non-trivial variation\n",
    "- Signals are plotted over time and respond to video content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
